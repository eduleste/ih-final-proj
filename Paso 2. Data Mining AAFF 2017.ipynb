{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/eduardo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/eduardo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"data_listo_mining.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DENOMINACION_AF</th>\n",
       "      <th>CODIGO_FP</th>\n",
       "      <th>D_CONTENIDOS</th>\n",
       "      <th>D_OBJETIVOS</th>\n",
       "      <th>CODIGO_AREA_TRAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FORMACION MODIFICACION DEL RCF</td>\n",
       "      <td>Formación complementaria</td>\n",
       "      <td>1. Establecimiento, operación y restablecimien...</td>\n",
       "      <td>Dar a conocer el contenido más significativo d...</td>\n",
       "      <td>Competencia clave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>INGLÉS TÉCNICO-MARÍTMO DE ESTIBA</td>\n",
       "      <td>Formación complementaria</td>\n",
       "      <td>- Conceptos elementales de gramática.  - Salud...</td>\n",
       "      <td>- Difundir la lengua inglesa como herramienta ...</td>\n",
       "      <td>Lenguas extranjeras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CAP FORMACION CONTINUA MERCANCIAS / VIAJEROS</td>\n",
       "      <td>Transporte y mantenimiento de vehículos</td>\n",
       "      <td>BLOQUE I: CONDUCCION RACIONAL BASADA EN LAS NO...</td>\n",
       "      <td>Conocer las características de la cadena cinem...</td>\n",
       "      <td>Conducción de vehículos por carretera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ALERGIAS E INTOLERANCIAS ALIMENTARIAS</td>\n",
       "      <td>Industrias alimentarias</td>\n",
       "      <td>TEMA 1. ALERGIAS E INTOLERANCIAS ALIMENTARIAS ...</td>\n",
       "      <td>La creciente preocupación de la sociedad y de ...</td>\n",
       "      <td>Alimentos diversos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>EXECUTIVE HOUSEKEEPING MANAGER</td>\n",
       "      <td>Hostelería y turismo</td>\n",
       "      <td>Modulo I: REGIDURIA DE PISOS. GOBERNANTA DE HO...</td>\n",
       "      <td>Dar toda la formación y habilidades necesarias...</td>\n",
       "      <td>Alojamiento</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                               DENOMINACION_AF  \\\n",
       "0           0                FORMACION MODIFICACION DEL RCF   \n",
       "1           1              INGLÉS TÉCNICO-MARÍTMO DE ESTIBA   \n",
       "2           2  CAP FORMACION CONTINUA MERCANCIAS / VIAJEROS   \n",
       "3           3         ALERGIAS E INTOLERANCIAS ALIMENTARIAS   \n",
       "4           4                EXECUTIVE HOUSEKEEPING MANAGER   \n",
       "\n",
       "                                 CODIGO_FP  \\\n",
       "0                 Formación complementaria   \n",
       "1                 Formación complementaria   \n",
       "2  Transporte y mantenimiento de vehículos   \n",
       "3                  Industrias alimentarias   \n",
       "4                     Hostelería y turismo   \n",
       "\n",
       "                                        D_CONTENIDOS  \\\n",
       "0  1. Establecimiento, operación y restablecimien...   \n",
       "1  - Conceptos elementales de gramática.  - Salud...   \n",
       "2  BLOQUE I: CONDUCCION RACIONAL BASADA EN LAS NO...   \n",
       "3  TEMA 1. ALERGIAS E INTOLERANCIAS ALIMENTARIAS ...   \n",
       "4  Modulo I: REGIDURIA DE PISOS. GOBERNANTA DE HO...   \n",
       "\n",
       "                                         D_OBJETIVOS  \\\n",
       "0  Dar a conocer el contenido más significativo d...   \n",
       "1  - Difundir la lengua inglesa como herramienta ...   \n",
       "2  Conocer las características de la cadena cinem...   \n",
       "3  La creciente preocupación de la sociedad y de ...   \n",
       "4  Dar toda la formación y habilidades necesarias...   \n",
       "\n",
       "                        CODIGO_AREA_TRAD  \n",
       "0                      Competencia clave  \n",
       "1                    Lenguas extranjeras  \n",
       "2  Conducción de vehículos por carretera  \n",
       "3                     Alimentos diversos  \n",
       "4                            Alojamiento  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1954, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          formacion modificacion del rcf\n",
       "1                        inglés técnico-marítmo de estiba\n",
       "2            cap formacion continua mercancias / viajeros\n",
       "3                   alergias e intolerancias alimentarias\n",
       "4                          executive housekeeping manager\n",
       "5                      prl para operadores en puente-grua\n",
       "6                                               word 2013\n",
       "7                                 word 2013 inicial medio\n",
       "8                                   prl primeros auxilios\n",
       "9       implantación de nuevas metodologías de enseñan...\n",
       "10                          alemán a1.1 fundación linguam\n",
       "11      analisis económico financiero de la empresa, f...\n",
       "12      prevención de riesgos en el sector de la const...\n",
       "13                     planes de evacuación y emergencias\n",
       "14      preparación certificate in advanced english (cae)\n",
       "15                            gruas transtainer practicas\n",
       "16                                                      i\n",
       "17      dirección y gestión de empresas de transporte ...\n",
       "18              formación lingüística para el profesorado\n",
       "19                                       curso inglés 33h\n",
       "20               prevención de riesgos laborales básico a\n",
       "21                          cambio de estacion a estacion\n",
       "22      curso directores de centros de servicios socia...\n",
       "23                                               itc nave\n",
       "24               actualizacion rcf licencia-trabajos raei\n",
       "25                                           itc arranque\n",
       "26                                         itc transporte\n",
       "27               p.g. cortes de tension 25 kv,3 kv,1,5 kv\n",
       "28                      corrección profesional on line ii\n",
       "29      curso internacional experto en coaching person...\n",
       "                              ...                        \n",
       "1924                                          advanced c1\n",
       "1925                             curso formacion cat1000s\n",
       "1926                                 inglés a1- elemental\n",
       "1927                      evaluación por competencias eso\n",
       "1928                                extensivo inglés b2.1\n",
       "1929                           inglés inicial b1 sumitomo\n",
       "1930                                   inglés a1 beginner\n",
       "1931                                   experto en compras\n",
       "1932    curso de gestion de nominas y seguros sociales...\n",
       "1933                        gestión de una clínica dental\n",
       "1934                      inglés a2.1 pre- intermediate 1\n",
       "1935                   formación continua cap conductores\n",
       "1936    prl para profesionales de mantenimiento en el ...\n",
       "1937                    formacion retocador montaje motor\n",
       "1938                        curso preparacion al advanced\n",
       "1939           programa de dirección estratégica de pymes\n",
       "1940                  herramientas google para docentes 2\n",
       "1941    metodología lean six sigma nivel green belt (m...\n",
       "1942             psicomotricidad en la educación infantil\n",
       "1943                       liderazgo para jefes de equipo\n",
       "1944                            sumitomo inglés básico a1\n",
       "1945                       inglés - b2 upper intermediate\n",
       "1946                                   angles b2 conversa\n",
       "1947        reciclaje y reincorporación agente de tranvía\n",
       "1948                                  marketing emocional\n",
       "1949                                  grupo 1: a2 (enero)\n",
       "1950                        refuerzo inglés rrhh parte ii\n",
       "1951          formación en seguros grupo a. segunda parte\n",
       "1952    dirección y gestión de organizaciones no guber...\n",
       "1953                                  grupo 2: a2 (enero)\n",
       "Name: DENOMINACION_AF, Length: 1954, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['DENOMINACION_AF'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1954, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "data2['Languagereveiw'] = data2['D_CONTENIDOS'].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2[data2['Languagereveiw'] != 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1593, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texts  ==>  Stop words removal ==> Punctuation free ==> Word Lemmatization ==> Digit removal ==> Feature Extraction (Tf-Idf) ==> Model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/eduardo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/eduardo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = stopwords.words('spanish')\n",
    "\n",
    "lemma=WordNetLemmatizer()\n",
    "token=ToktokTokenizer() #EN ppio deberia funcionar con castellano\n",
    "stemmer = SnowballStemmer('spanish', ignore_stopwords=True)\n",
    "\n",
    "#tokenizer = nltk.data.load('tokenizers/punkt/spanish.pickle')\n",
    "def clean_up(text): \n",
    "    '''\n",
    "    # clean all but alpha or ' '\n",
    "    st=\"1234567890-=~@#$%^&*()_+[!{;”:\\’><.,/?”}]\"\n",
    "    for w in text:\n",
    "        if w in st:\n",
    "            text=text.replace(w,\"\")\n",
    "            '''\n",
    "    return ''.join(ch for ch in text if ch.isalpha() or ch == ' ') # [a-zA-Z\\s]\n",
    "\n",
    "def tokenizar(text): \n",
    "    # string and returns list: split by ' ', '\\n'\n",
    "    word=token.tokenize(text)\n",
    "    return (word)\n",
    "\n",
    "def stem_and_lemmanize(word): #Probar es-lemmatize y SpaCy\n",
    "    listLemma = []\n",
    "    stem = [stemmer.stem(word) for word in word]\n",
    "    for w in stem:\n",
    "        x=lemma.lemmatize(w)\n",
    "        listLemma.append(x)\n",
    "    return \" \".join(listLemma).lower()\n",
    "\n",
    "def only_stem(word): \n",
    "    stem = [stemmer.stem(word) for word in word]\n",
    "    return \" \".join(stem).lower()\n",
    "\n",
    "def stopWordsRemove(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words('spanish')])\n",
    "    #stop = set(stopwords.words('spanish'))\n",
    "    #wordList =[x.lower().strip() for x in text]\n",
    "    #removedList=[x for x in wordList if x not in stop]\n",
    "    #text=\" \".join(removedList)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def get_words(text): \n",
    "    limpio = clean_up(text)\n",
    "    lista = tokenizar(limpio)\n",
    "    lista2 = only_stem(lista)\n",
    "    res = stopWordsRemove(lista2)\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hola esto es un curso de estos de machine learning el curso se da en español e inglés como estamos en España   molamos  con los cursos que cursamos Trabajo trabajamos trabajadores'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = 'hola esto es un curso: de estos!!! de machine learning, el curso se da en: español e inglés. como estamos en España,  1 molamos # con los cursos que cursamos. Trabajo, trabajamos, trabajadores'\n",
    "\n",
    "st=clean_up(st)\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola',\n",
       " 'esto',\n",
       " 'es',\n",
       " 'un',\n",
       " 'curso',\n",
       " 'de',\n",
       " 'estos',\n",
       " 'de',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'el',\n",
       " 'curso',\n",
       " 'se',\n",
       " 'da',\n",
       " 'en',\n",
       " 'español',\n",
       " 'e',\n",
       " 'inglés',\n",
       " 'como',\n",
       " 'estamos',\n",
       " 'en',\n",
       " 'España',\n",
       " 'molamos',\n",
       " 'con',\n",
       " 'los',\n",
       " 'cursos',\n",
       " 'que',\n",
       " 'cursamos',\n",
       " 'Trabajo',\n",
       " 'trabajamos',\n",
       " 'trabajadores']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st1=tokenizar(st)\n",
    "st1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hol esto e un cur de estos de machin learning el cur se da en español e ingles como estamos en españ mol con los cur que cur trabaj trabaj trabaj'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st2 = stem_and_lemmanize(st1)\n",
    "st2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hol cur machin learning cur da español ingles españ mol cur cur trabaj trabaj trabaj'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWordsRemove(st2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hol curs machin learning curs da español ingles españ mol curs curs trabaj trabaj trabaj'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words(st)\n",
    "'hol curs machin learning curs da español ingles españ mol curs curs trabaj trabaj trabaj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosa = 'hola esto es un curso: de estos!!! de machine learning, el curso se da en: español e inglés. como estamos en España,  1 molamos # con los cursos que cursamos. Trabajo, trabajamos, trabajadores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hola esto es un curso de estos de machine learning el curso se da en español e inglés como estamos en España   molamos  con los cursos que cursamos Trabajo trabajamos trabajadores'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosa1 = clean_up(cosa)\n",
    "cosa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola',\n",
       " 'esto',\n",
       " 'es',\n",
       " 'un',\n",
       " 'curso',\n",
       " 'de',\n",
       " 'estos',\n",
       " 'de',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'el',\n",
       " 'curso',\n",
       " 'se',\n",
       " 'da',\n",
       " 'en',\n",
       " 'español',\n",
       " 'e',\n",
       " 'inglés',\n",
       " 'como',\n",
       " 'estamos',\n",
       " 'en',\n",
       " 'España',\n",
       " 'molamos',\n",
       " 'con',\n",
       " 'los',\n",
       " 'cursos',\n",
       " 'que',\n",
       " 'cursamos',\n",
       " 'Trabajo',\n",
       " 'trabajamos',\n",
       " 'trabajadores']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosa2 = tokenizar(cosa1)\n",
    "cosa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hol esto es un curs de estos de machin learning el curs se da en español e ingles como estamos en españ mol con los curs que curs trabaj trabaj trabaj'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosa3 = only_stem(cosa2)\n",
    "cosa3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hol curs machin learning curs da español ingles españ mol curs curs trabaj trabaj trabaj'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosa4 = stopWordsRemove(cosa3)\n",
    "cosa4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['D_CONTENIDOS']=data2['D_CONTENIDOS'].apply(get_words)\n",
    "\n",
    "#get_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DENOMINACION_AF</th>\n",
       "      <th>CODIGO_FP</th>\n",
       "      <th>D_CONTENIDOS</th>\n",
       "      <th>D_OBJETIVOS</th>\n",
       "      <th>CODIGO_AREA_TRAD</th>\n",
       "      <th>Languagereveiw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FORMACION MODIFICACION DEL RCF</td>\n",
       "      <td>Formación complementaria</td>\n",
       "      <td>establec oper restablec bloque telefon situaci...</td>\n",
       "      <td>Dar a conocer el contenido más significativo d...</td>\n",
       "      <td>Competencia clave</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INGLÉS TÉCNICO-MARÍTMO DE ESTIBA</td>\n",
       "      <td>Formación complementaria</td>\n",
       "      <td>concept elemental gramat salud expresion socia...</td>\n",
       "      <td>- Difundir la lengua inglesa como herramienta ...</td>\n",
       "      <td>Lenguas extranjeras</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAP FORMACION CONTINUA MERCANCIAS / VIAJEROS</td>\n",
       "      <td>Transporte y mantenimiento de vehículos</td>\n",
       "      <td>bloqu i conduccion racional bas norm segur con...</td>\n",
       "      <td>Conocer las características de la cadena cinem...</td>\n",
       "      <td>Conducción de vehículos por carretera</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALERGIAS E INTOLERANCIAS ALIMENTARIAS</td>\n",
       "      <td>Industrias alimentarias</td>\n",
       "      <td>tem alergi intoler alimentari alergi intoler c...</td>\n",
       "      <td>La creciente preocupación de la sociedad y de ...</td>\n",
       "      <td>Alimentos diversos</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXECUTIVE HOUSEKEEPING MANAGER</td>\n",
       "      <td>Hostelería y turismo</td>\n",
       "      <td>modul i regiduri pis gobernant hotel hras modu...</td>\n",
       "      <td>Dar toda la formación y habilidades necesarias...</td>\n",
       "      <td>Alojamiento</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                DENOMINACION_AF  \\\n",
       "0                FORMACION MODIFICACION DEL RCF   \n",
       "1              INGLÉS TÉCNICO-MARÍTMO DE ESTIBA   \n",
       "2  CAP FORMACION CONTINUA MERCANCIAS / VIAJEROS   \n",
       "3         ALERGIAS E INTOLERANCIAS ALIMENTARIAS   \n",
       "4                EXECUTIVE HOUSEKEEPING MANAGER   \n",
       "\n",
       "                                 CODIGO_FP  \\\n",
       "0                 Formación complementaria   \n",
       "1                 Formación complementaria   \n",
       "2  Transporte y mantenimiento de vehículos   \n",
       "3                  Industrias alimentarias   \n",
       "4                     Hostelería y turismo   \n",
       "\n",
       "                                        D_CONTENIDOS  \\\n",
       "0  establec oper restablec bloque telefon situaci...   \n",
       "1  concept elemental gramat salud expresion socia...   \n",
       "2  bloqu i conduccion racional bas norm segur con...   \n",
       "3  tem alergi intoler alimentari alergi intoler c...   \n",
       "4  modul i regiduri pis gobernant hotel hras modu...   \n",
       "\n",
       "                                         D_OBJETIVOS  \\\n",
       "0  Dar a conocer el contenido más significativo d...   \n",
       "1  - Difundir la lengua inglesa como herramienta ...   \n",
       "2  Conocer las características de la cadena cinem...   \n",
       "3  La creciente preocupación de la sociedad y de ...   \n",
       "4  Dar toda la formación y habilidades necesarias...   \n",
       "\n",
       "                        CODIGO_AREA_TRAD Languagereveiw  \n",
       "0                      Competencia clave             es  \n",
       "1                    Lenguas extranjeras             es  \n",
       "2  Conducción de vehículos por carretera             es  \n",
       "3                     Alimentos diversos             es  \n",
       "4                            Alojamiento             pt  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop = set(stopwords.words('spanish'))\n",
    "#exclude = set(string.punctuation)\n",
    "#lemma = WordNetLemmatizer()\n",
    " \n",
    "# Cleaning the text sentences so that punctuation marks, stop words & digits are removed\n",
    "#def clean(doc):\n",
    "    #stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purga_numeros_caracteres1(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub('\\W', ' ', texto)\n",
    "    texto = re.sub('\\s+', ' ', texto)\n",
    "    texto = texto.strip(' ')\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'columns = ['DENOMINACION_AF','CODIGO_FP', 'D_CONTENIDOS', 'D_OBJETIVOS', 'CODIGO_AREA_TRAD']\\nfor colum in columns:\\n    data2[colum]=data2[colum].apply(purga_numeros_caracteres1)\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''columns = ['DENOMINACION_AF','CODIGO_FP', 'D_CONTENIDOS', 'D_OBJETIVOS', 'CODIGO_AREA_TRAD']\n",
    "for colum in columns:\n",
    "    data2[colum]=data2[colum].apply(purga_numeros_caracteres1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'establec oper restablec bloque telefon situacion anormal banaliz temporal via entreg via bloqu coordin respons circul puntualiz prescripcion circul situacion degrad consign libr telefonem'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['D_CONTENIDOS'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'practic oral intens estructur vocabulari ingles expresion social expres opinion ofert invit peticion cortes funcion tipic viaj reunion trabaj congres etc'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['D_CONTENIDOS'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'from sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.cluster import KMeans\\nimport nltk \\nnltk.download(\\'stopwords\\')\\nnltk.download(\\'wordnet\\')\\nfrom nltk.corpus import stopwords\\nfrom nltk.stem.wordnet import WordNetLemmatizer\\nimport string\\nimport re\\nimport numpy as np\\nfrom collections import Counter\\n\\n \\nstop = set(stopwords.words(\\'spanish\\'))\\nexclude = set(string.punctuation)\\nlemma = WordNetLemmatizer()\\n \\n# Cleaning the text sentences so that punctuation marks, stop words & digits are removed\\ndef clean(doc):\\n    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\\n    punc_free = \\'\\'.join(ch for ch in stop_free if ch not in exclude)\\n    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\\n    processed = re.sub(r\"\\\\d+\",\"\",normalized)\\n    y = processed.split()\\n    return y'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter''''''\n",
    "\n",
    " \n",
    "stop = set(stopwords.words('spanish'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    " \n",
    "# Cleaning the text sentences so that punctuation marks, stop words & digits are removed\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    processed = re.sub(r\"\\d+\",\"\",normalized)\n",
    "    y = processed.split()\n",
    "    return y'''''\n",
    "    \n",
    "\n",
    "     \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('preparado_para_algoritmo.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'establecimiento operación restablecimiento bloqueo telefónico situacion anormalidad banalización tempor vía entrega vía bloqueada coordinación entr respons circulación puntualizacion sobr prescripcion circulación situacion degradadas consigna libro telefonema'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'establecimiento operación restablecimiento bloqueo telefónico situacion anormalidad banalización tempor vía entrega vía bloqueada coordinación entr respons circulación puntualizacion sobr prescripcion circulación situacion degradadas consigna libro telefonema'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
